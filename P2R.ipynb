{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.8.19 (default, Mar 20 2024, 15:27:52) \n",
      "[Clang 14.0.6 ]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=8, micro=19, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T21:11:30.011794Z",
     "start_time": "2024-04-22T21:11:30.006499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Notes: \n",
    "# #torch\n",
    "#!pip install transformers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plate2Recipe Project\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Collection and Preprocessing\n",
    "\n",
    "\n",
    "- Data loading: *use food-101.tar.gz for CNN and full_dataset.csv for NLP* (https://drive.google.com/drive/folders/1ui_zS11_ENZTCNLUsgg_UwAYr-ZaLbac)\n",
    "- Data cleaning\n",
    "- Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/food-101.tar.gz\n",
      "Extracting ./data/food-101.tar.gz to ./data/\n"
     ]
    }
   ],
   "source": [
    "# CNN - Load and Transform Data\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "root_dir = './data/'\n",
    "\n",
    "train_dataset = datasets.Food101(root=root_dir, split='train', transform=train_transforms, download=True)\n",
    "valid_dataset = datasets.Food101(root=root_dir, split='test', transform=valid_transforms, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:45:27.211698Z",
     "start_time": "2024-04-22T22:44:18.485527Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "                   title                                        ingredients  \\\n0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n\n                                          directions  \\\n0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n1  [\"Place chipped beef on bottom of baking dish....   \n2  [\"In a slow cooker, combine all ingredients. C...   \n3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n4  [\"Combine first four ingredients and press in ...   \n\n                                              link    source  \\\n0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n\n                                                 NER  \n0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>link</th>\n      <th>source</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No-Bake Nut Cookies</td>\n      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n      <td>Gathered</td>\n      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jewell Ball'S Chicken</td>\n      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n      <td>[\"Place chipped beef on bottom of baking dish....</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n      <td>Gathered</td>\n      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Creamy Corn</td>\n      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n      <td>Gathered</td>\n      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chicken Funny</td>\n      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=897570</td>\n      <td>Gathered</td>\n      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Reeses Cups(Candy)</td>\n      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n      <td>[\"Combine first four ingredients and press in ...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=659239</td>\n      <td>Gathered</td>\n      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP - Load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "recipes = pd.read_csv('./data/full_dataset.csv', encoding='UTF-8')\n",
    "recipes = recipes.drop(recipes.columns[0], axis=1)\n",
    "recipes.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T03:41:46.078663Z",
     "start_time": "2024-04-23T03:41:18.607336Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Development\n",
    "- CNN for Image Processing\n",
    "- NLP for Recipe Generation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLP Model\n",
    "- Assume list of ingredients is provided, we can use this to generate the recipe. \n",
    "- Match input list of ingredients with the ingredients in the dataset and generate the recipe\n",
    "- Approaches:\n",
    "        -- Best Matching using Cosine Similarity: The chosen recipe will be the one with the highest similarity score\n",
    "        -- GPT2 model\n",
    "        -- ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# Assume 'user_ingredients' list is already defined\n",
    "user_ingredients = ['chicken', 'onion', 'pepper']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T02:47:13.855199Z",
     "start_time": "2024-04-23T02:47:13.851482Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- #### Using TF-IDF for vectorization & cosine similarity for best matching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Matching Recipe: My Chopped Chicken Liver\n",
      "Ingredients: [\"1 lb chicken liver\", \"3 tablespoons chicken fat (SHMALTZ)\", \"1 onion, diced\", \"3 hard-boiled eggs, chopped\", \"salt\", \"pepper\", \"onion powder\", \"garlic powder\"]\n",
      "Directions: [\"In microwave, cook chicken livers and fat until done, about 5 minutes (use a pie dish).\", \"Remove livers with a slotted spoon, add onions and microwave until cooked, about 3 minutes.\", \"Meanwhile hard boil eggs in saucepan until done.\", \"Add livers, fat and onions to food processor; pulse until all ingredients are chopped fine.\", \"Mash eggs and add seasoning.\", \"Add liver mixture to egg mixture.\", \"Serve chopped liver on greens, surrounded by tomatoes, and lettuce.\", \"Serve with toast points or crackers.\"]\n"
     ]
    }
   ],
   "source": [
    "# using TF-IDF for vectorization and cosine similarity for matching\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Preprocess data:\n",
    "def preprocess(ingredients):\n",
    "    return [' '.join(eval(ing)).lower().replace('[^a-z\\s]', '') for ing in ingredients]\n",
    "\n",
    "# VECTORIZE\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorize ingredients: \n",
    "recipe_ingredients = preprocess(recipes['NER'])\n",
    "recipe_tfidf = vectorizer.fit_transform(recipe_ingredients)\n",
    "\n",
    "# Vectorize user ingredients:\n",
    "user_ingredients_string = ' '.join(user_ingredients).lower()\n",
    "user_tfidf = vectorizer.transform([user_ingredients_string])\n",
    "\n",
    "\n",
    "# COMPUTE COSINE SIMILARITY\n",
    "similarity_scores = cosine_similarity(user_tfidf, recipe_tfidf)\n",
    "\n",
    "# Select the best matching recipe\n",
    "best_match_index = similarity_scores.argmax()\n",
    "best_recipe = recipes.iloc[best_match_index]\n",
    "\n",
    "print(\"Best Matching Recipe:\", best_recipe['title'])\n",
    "print(\"Ingredients:\", best_recipe['ingredients'])\n",
    "print(\"Directions:\", best_recipe['directions'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T02:48:03.850175Z",
     "start_time": "2024-04-23T02:47:21.613933Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- #### Using GPT-2: \n",
    "This approach combines traditional NLP techniques for ingredient matching with advanced language generation capabilities of GPT-2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients: chicken, onion, pepper; Recipe: My Chopped Chicken Liver - Directions: Preheat oven to 350 degrees F. Line a baking sheet with parchment paper and set aside. In a large bowl, whisk together the olive oil, salt, and pepper. Add the chicken mixture to the dry ingredients and mix well. Pour the mixture into the prepared baking dish and bake for 20-25 minutes, or until golden brown. Remove from the oven and allow to cool completely before serving.\n"
     ]
    }
   ],
   "source": [
    "# Use GPT-2 to generate a Recipe\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Input Text to GPT-2: provide context to GPT-2 for generating the recipe. The format & content can be adjusted based on how we want GPT-2 to expand the recipe information.\n",
    "text = f\"Ingredients: {', '.join(user_ingredients)}; Recipe: {best_recipe['title']} - Directions:\"\n",
    "\n",
    "# Encode the text input\n",
    "indexed_tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "# Generate a text using the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(tokens_tensor, max_length=300, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T03:22:23.727685Z",
     "start_time": "2024-04-23T03:22:14.012220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "- Model compilation\n",
    "- Model training\n",
    "- Hyperparameter tuning\n",
    "\n",
    "## Evaluation\n",
    "- Model evaluation metrics\n",
    "- Visualization of results\n",
    "\n",
    "## Conclusion\n",
    "- Summary of findings\n",
    "- Future work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-p2r-py",
   "language": "python",
   "display_name": "Python [conda env:p2r] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
